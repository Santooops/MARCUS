{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Setup] Seed=42\n",
      "[Data] Loading region_dict + csv...\n",
      "[Data] y_next mean=2925.0990, std=782.3510\n",
      "[Data] Train=4071 Val=1062 Test=1062\n",
      "[Model] Loading no-rent Marcus backbone...\n",
      "[Model] Backbone loaded + frozen\n",
      "\n",
      "[Training] LR=0.0005 WD=0.0001 Epochs=800\n",
      "Epoch   0 | TrainLoss 0.3135 | ValMSE 0.7645 | ValMAE 0.5773 | LR 0.000500 | Wait 0/50\n",
      "Epoch   1 | TrainLoss 0.2149 | ValMSE 0.5375 | ValMAE 0.4655 | LR 0.000500 | Wait 0/50\n",
      "Epoch   2 | TrainLoss 0.1700 | ValMSE 0.4258 | ValMAE 0.3966 | LR 0.000500 | Wait 0/50\n",
      "Epoch   3 | TrainLoss 0.1392 | ValMSE 0.3432 | ValMAE 0.3464 | LR 0.000500 | Wait 0/50\n",
      "Epoch   4 | TrainLoss 0.1279 | ValMSE 0.2815 | ValMAE 0.3118 | LR 0.000500 | Wait 0/50\n",
      "Epoch   5 | TrainLoss 0.1146 | ValMSE 0.2609 | ValMAE 0.3047 | LR 0.000500 | Wait 0/50\n",
      "Epoch   6 | TrainLoss 0.1036 | ValMSE 0.2154 | ValMAE 0.2847 | LR 0.000500 | Wait 0/50\n",
      "Epoch   7 | TrainLoss 0.0941 | ValMSE 0.1840 | ValMAE 0.2596 | LR 0.000500 | Wait 0/50\n",
      "Epoch   8 | TrainLoss 0.0912 | ValMSE 0.1727 | ValMAE 0.2616 | LR 0.000500 | Wait 0/50\n",
      "Epoch   9 | TrainLoss 0.0839 | ValMSE 0.1534 | ValMAE 0.2534 | LR 0.000500 | Wait 0/50\n",
      "Epoch  10 | TrainLoss 0.0831 | ValMSE 0.1373 | ValMAE 0.2284 | LR 0.000500 | Wait 0/50\n",
      "Epoch  11 | TrainLoss 0.0737 | ValMSE 0.1366 | ValMAE 0.2409 | LR 0.000500 | Wait 0/50\n",
      "Epoch  12 | TrainLoss 0.0764 | ValMSE 0.1242 | ValMAE 0.2268 | LR 0.000500 | Wait 0/50\n",
      "Epoch  15 | TrainLoss 0.0689 | ValMSE 0.1149 | ValMAE 0.2231 | LR 0.000500 | Wait 0/50\n",
      "Epoch  16 | TrainLoss 0.0648 | ValMSE 0.1020 | ValMAE 0.2121 | LR 0.000500 | Wait 0/50\n",
      "Epoch  17 | TrainLoss 0.0662 | ValMSE 0.0967 | ValMAE 0.2080 | LR 0.000500 | Wait 0/50\n",
      "Epoch  18 | TrainLoss 0.0625 | ValMSE 0.0947 | ValMAE 0.2098 | LR 0.000500 | Wait 0/50\n",
      "Epoch  20 | TrainLoss 0.0577 | ValMSE 0.0999 | ValMAE 0.2143 | LR 0.000500 | Wait 2/50\n",
      "Epoch  22 | TrainLoss 0.0550 | ValMSE 0.0821 | ValMAE 0.1973 | LR 0.000500 | Wait 0/50\n",
      "Epoch  28 | TrainLoss 0.0528 | ValMSE 0.0735 | ValMAE 0.1814 | LR 0.000500 | Wait 0/50\n",
      "Epoch  33 | TrainLoss 0.0496 | ValMSE 0.0702 | ValMAE 0.1759 | LR 0.000500 | Wait 0/50\n",
      "Epoch  37 | TrainLoss 0.0463 | ValMSE 0.0667 | ValMAE 0.1772 | LR 0.000500 | Wait 0/50\n",
      "Epoch  40 | TrainLoss 0.0468 | ValMSE 0.0806 | ValMAE 0.1937 | LR 0.000500 | Wait 3/50\n",
      "Epoch  43 | TrainLoss 0.0428 | ValMSE 0.0620 | ValMAE 0.1658 | LR 0.000500 | Wait 0/50\n",
      "Epoch  57 | TrainLoss 0.0366 | ValMSE 0.0590 | ValMAE 0.1657 | LR 0.000500 | Wait 0/50\n",
      "Epoch  58 | TrainLoss 0.0365 | ValMSE 0.0564 | ValMAE 0.1590 | LR 0.000500 | Wait 0/50\n",
      "Epoch  60 | TrainLoss 0.0406 | ValMSE 0.0617 | ValMAE 0.1684 | LR 0.000500 | Wait 2/50\n",
      "Epoch  64 | TrainLoss 0.0404 | ValMSE 0.0551 | ValMAE 0.1577 | LR 0.000500 | Wait 0/50\n",
      "Epoch  78 | TrainLoss 0.0347 | ValMSE 0.0537 | ValMAE 0.1588 | LR 0.000500 | Wait 0/50\n",
      "Epoch  79 | TrainLoss 0.0352 | ValMSE 0.0526 | ValMAE 0.1556 | LR 0.000500 | Wait 0/50\n",
      "Epoch  80 | TrainLoss 0.0371 | ValMSE 0.0585 | ValMAE 0.1630 | LR 0.000500 | Wait 1/50\n",
      "Epoch  99 | TrainLoss 0.0310 | ValMSE 0.0513 | ValMAE 0.1487 | LR 0.000250 | Wait 0/50\n",
      "Epoch 100 | TrainLoss 0.0319 | ValMSE 0.0635 | ValMAE 0.1718 | LR 0.000250 | Wait 1/50\n",
      "Epoch 110 | TrainLoss 0.0328 | ValMSE 0.0513 | ValMAE 0.1567 | LR 0.000250 | Wait 0/50\n",
      "Epoch 115 | TrainLoss 0.0329 | ValMSE 0.0509 | ValMAE 0.1513 | LR 0.000250 | Wait 0/50\n",
      "Epoch 117 | TrainLoss 0.0347 | ValMSE 0.0508 | ValMAE 0.1547 | LR 0.000250 | Wait 0/50\n",
      "Epoch 120 | TrainLoss 0.0320 | ValMSE 0.0567 | ValMAE 0.1608 | LR 0.000250 | Wait 3/50\n",
      "Epoch 124 | TrainLoss 0.0325 | ValMSE 0.0503 | ValMAE 0.1564 | LR 0.000250 | Wait 0/50\n",
      "Epoch 139 | TrainLoss 0.0320 | ValMSE 0.0485 | ValMAE 0.1547 | LR 0.000250 | Wait 0/50\n",
      "Epoch 140 | TrainLoss 0.0329 | ValMSE 0.0558 | ValMAE 0.1611 | LR 0.000250 | Wait 1/50\n",
      "Epoch 160 | TrainLoss 0.0289 | ValMSE 0.0656 | ValMAE 0.1754 | LR 0.000125 | Wait 21/50\n",
      "Epoch 180 | TrainLoss 0.0325 | ValMSE 0.0599 | ValMAE 0.1650 | LR 0.000063 | Wait 41/50\n",
      "\n",
      "[Training] Early stop at epoch 189\n",
      "\n",
      "[Testing] Evaluating best head on test set...\n",
      "[Testing] Loaded best head from epoch 139 (val_mse=0.048470)\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS (No-Rent Marcus Backbone)  [Predict y(t+1)]\n",
      "============================================================\n",
      "MAE:  139.8979\n",
      "RMSE: 213.8654\n",
      "MAPE: 4.51%\n",
      "R²:   0.9359\n",
      "============================================================\n",
      "\n",
      "[Done]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# No-Rent Marcus Backbone -> RentIndex(t+1) Regression\n",
    "# POI + Census + Traffic only\n",
    "# ============================================================\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import os\n",
    "import random\n",
    "\n",
    "from marcus_new import MarcusModel\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "LR = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MAX_EPOCHS = 800\n",
    "PATIENCE = 50\n",
    "SEED = 42\n",
    "\n",
    "HIDDEN_DIM = 64\n",
    "NUM_TIME = 36\n",
    "\n",
    "REGION_DICT_PATH = \"region_dict.pkl\"\n",
    "TRAIN_PATH = \"rent_index/train.csv\"\n",
    "VAL_PATH   = \"rent_index/val.csv\"\n",
    "TEST_PATH  = \"rent_index/test.csv\"\n",
    "\n",
    "# csv 里 y(t+1) 在 y_next\n",
    "TARGET_COL = \"y_next\"\n",
    "\n",
    "# no-rent backbone ckpt\n",
    "MARCUS_CKPT = \"best_marcus_backbone.pt\"\n",
    "\n",
    "OUT_BEST_HEAD = \"best_marcus_rentindex.pt\"\n",
    "\n",
    "# ============================================================\n",
    "# Reproducibility\n",
    "# ============================================================\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "print(f\"[Setup] Seed={SEED}\")\n",
    "\n",
    "# ============================================================\n",
    "# Dataset (NO RENT in features)\n",
    "# ============================================================\n",
    "\n",
    "class RentIndexDataset(Dataset):\n",
    "    def __init__(self, region_dict, df, y_col):\n",
    "        self.region_dict = region_dict\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.y_col = y_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # 输入特征来自 (t) 的 year_month\n",
    "        key = (int(row[\"modzcta\"]), str(row[\"year_month\"]))\n",
    "        item = self.region_dict[key]\n",
    "\n",
    "        return {\n",
    "            \"poi\": item[\"poi\"][\"missing\"],\n",
    "            \"census\": item[\"census\"][\"missing\"],\n",
    "            \"traffic\": item[\"traffic\"][\"missing\"],\n",
    "            \"time_idx\": item[\"time_idx\"],\n",
    "            \"y\": row[self.y_col],   # y_norm of y_next\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"poi\": torch.tensor(np.stack([b[\"poi\"] for b in batch]), dtype=torch.float, device=DEVICE),\n",
    "        \"census\": torch.tensor(np.stack([b[\"census\"] for b in batch]), dtype=torch.float, device=DEVICE),\n",
    "        \"traffic\": torch.tensor(np.stack([b[\"traffic\"] for b in batch]), dtype=torch.float, device=DEVICE),\n",
    "        \"time_idx\": torch.tensor([b[\"time_idx\"] for b in batch], dtype=torch.long, device=DEVICE),\n",
    "        \"y\": torch.tensor([b[\"y\"] for b in batch], dtype=torch.float, device=DEVICE),\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Load Data\n",
    "# ============================================================\n",
    "\n",
    "print(\"[Data] Loading region_dict + csv...\")\n",
    "\n",
    "with open(REGION_DICT_PATH, \"rb\") as f:\n",
    "    region_dict = pickle.load(f)\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df   = pd.read_csv(VAL_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# standardize label: fit on train y_next\n",
    "y_mean = train_df[TARGET_COL].mean()\n",
    "y_std  = train_df[TARGET_COL].std()\n",
    "\n",
    "train_df[\"y_norm\"] = (train_df[TARGET_COL] - y_mean) / (y_std + 1e-8)\n",
    "val_df[\"y_norm\"]   = (val_df[TARGET_COL] - y_mean) / (y_std + 1e-8)\n",
    "test_df[\"y_norm\"]  = (test_df[TARGET_COL] - y_mean) / (y_std + 1e-8)\n",
    "\n",
    "print(f\"[Data] {TARGET_COL} mean={y_mean:.4f}, std={y_std:.4f}\")\n",
    "\n",
    "train_ds = RentIndexDataset(region_dict, train_df, \"y_norm\")\n",
    "val_ds   = RentIndexDataset(region_dict, val_df, \"y_norm\")\n",
    "test_ds  = RentIndexDataset(region_dict, test_df, \"y_norm\")\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,\n",
    "                          collate_fn=collate_fn, worker_init_fn=worker_init_fn)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False,\n",
    "                          collate_fn=collate_fn, worker_init_fn=worker_init_fn)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False,\n",
    "                          collate_fn=collate_fn, worker_init_fn=worker_init_fn)\n",
    "\n",
    "print(f\"[Data] Train={len(train_ds)} Val={len(val_ds)} Test={len(test_ds)}\")\n",
    "\n",
    "# ============================================================\n",
    "# Model: backbone (frozen) + regression head\n",
    "# ============================================================\n",
    "\n",
    "print(\"[Model] Loading no-rent Marcus backbone...\")\n",
    "\n",
    "backbone = MarcusModel(hidden_dim=HIDDEN_DIM, num_time=NUM_TIME).to(DEVICE)\n",
    "\n",
    "ckpt = torch.load(MARCUS_CKPT, map_location=DEVICE)\n",
    "backbone.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "\n",
    "backbone.eval()\n",
    "for p in backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "print(\"[Model] Backbone loaded + frozen\")\n",
    "\n",
    "# Regression head\n",
    "reg_head = nn.Sequential(\n",
    "    nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n",
    "    nn.BatchNorm1d(HIDDEN_DIM),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(HIDDEN_DIM, HIDDEN_DIM // 2),\n",
    "    nn.BatchNorm1d(HIDDEN_DIM // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(HIDDEN_DIM // 2, 1)\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = Adam(reg_head.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=15\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Loss (Huber)\n",
    "# ============================================================\n",
    "\n",
    "def huber_loss(pred, target, delta=1.0):\n",
    "    err = pred - target\n",
    "    abs_err = torch.abs(err)\n",
    "    loss = torch.where(\n",
    "        abs_err < delta,\n",
    "        0.5 * err ** 2,\n",
    "        delta * (abs_err - 0.5 * delta)\n",
    "    )\n",
    "    return loss.mean()\n",
    "\n",
    "# ============================================================\n",
    "# Train\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n[Training] LR={LR} WD={WEIGHT_DECAY} Epochs={MAX_EPOCHS}\")\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    reg_head.train()\n",
    "    total_train = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        with torch.no_grad():\n",
    "            h = backbone(\n",
    "                {\n",
    "                    \"poi\": batch[\"poi\"],\n",
    "                    \"census\": batch[\"census\"],\n",
    "                    \"traffic\": batch[\"traffic\"],\n",
    "                },\n",
    "                time_idx=batch[\"time_idx\"]\n",
    "            )\n",
    "\n",
    "        pred = reg_head(h).squeeze(-1)\n",
    "        loss = huber_loss(pred, batch[\"y\"], delta=1.0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(reg_head.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train += loss.item()\n",
    "\n",
    "    train_loss = total_train / len(train_loader)\n",
    "\n",
    "    # ---- Val ----\n",
    "    reg_head.eval()\n",
    "    with torch.no_grad():\n",
    "        preds, gts = [], []\n",
    "        for batch in val_loader:\n",
    "            h = backbone(\n",
    "                {\n",
    "                    \"poi\": batch[\"poi\"],\n",
    "                    \"census\": batch[\"census\"],\n",
    "                    \"traffic\": batch[\"traffic\"],\n",
    "                },\n",
    "                time_idx=batch[\"time_idx\"]\n",
    "            )\n",
    "            p = reg_head(h).squeeze(-1)\n",
    "            preds.append(p)\n",
    "            gts.append(batch[\"y\"])\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        gts = torch.cat(gts)\n",
    "\n",
    "        val_mse = F.mse_loss(preds, gts).item()\n",
    "        val_mae = F.l1_loss(preds, gts).item()\n",
    "\n",
    "    scheduler.step(val_mse)\n",
    "\n",
    "    # ---- Early stopping ----\n",
    "    if val_mse < best_val - 1e-5:\n",
    "        best_val = val_mse\n",
    "        wait = 0\n",
    "        torch.save(\n",
    "            {\"model\": reg_head.state_dict(), \"epoch\": epoch, \"val_mse\": val_mse},\n",
    "            OUT_BEST_HEAD\n",
    "        )\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    if epoch % 20 == 0 or wait == 0:\n",
    "        lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "        print(f\"Epoch {epoch:3d} | TrainLoss {train_loss:.4f} | ValMSE {val_mse:.4f} \"\n",
    "              f\"| ValMAE {val_mae:.4f} | LR {lr_now:.6f} | Wait {wait}/{PATIENCE}\")\n",
    "\n",
    "    if wait >= PATIENCE:\n",
    "        print(f\"\\n[Training] Early stop at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# ============================================================\n",
    "# Test\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n[Testing] Evaluating best head on test set...\")\n",
    "\n",
    "best = torch.load(\n",
    "    OUT_BEST_HEAD,\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False\n",
    ")\n",
    "reg_head.load_state_dict(best[\"model\"])\n",
    "reg_head.eval()\n",
    "\n",
    "print(f\"[Testing] Loaded best head from epoch {best['epoch']} (val_mse={best['val_mse']:.6f})\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds, gts = [], []\n",
    "    for batch in test_loader:\n",
    "        h = backbone(\n",
    "            {\n",
    "                \"poi\": batch[\"poi\"],\n",
    "                \"census\": batch[\"census\"],\n",
    "                \"traffic\": batch[\"traffic\"],\n",
    "            },\n",
    "            time_idx=batch[\"time_idx\"]\n",
    "        )\n",
    "        p = reg_head(h).squeeze(-1)\n",
    "        preds.append(p)\n",
    "        gts.append(batch[\"y\"])\n",
    "\n",
    "preds = torch.cat(preds).cpu().numpy()\n",
    "gts   = torch.cat(gts).cpu().numpy()\n",
    "\n",
    "# denormalize back to original y_next scale\n",
    "pred_raw = preds * (y_std + 1e-8) + y_mean\n",
    "gt_raw   = gts   * (y_std + 1e-8) + y_mean\n",
    "\n",
    "mae  = mean_absolute_error(gt_raw, pred_raw)\n",
    "rmse = np.sqrt(mean_squared_error(gt_raw, pred_raw))\n",
    "r2   = r2_score(gt_raw, pred_raw)\n",
    "\n",
    "eps = 1e-8\n",
    "mape = np.mean(np.abs((gt_raw - pred_raw) / (np.abs(gt_raw) + eps))) * 100.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST RESULTS (No-Rent Marcus Backbone)  [Predict y(t+1)]\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[Done]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8e708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  139.8979\n",
      "RMSE: 213.8654\n",
      "MAPE: 4.51%\n",
      "R²:   0.9359\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"R²:   {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marcusbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
